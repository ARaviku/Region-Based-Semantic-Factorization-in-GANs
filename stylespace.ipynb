{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "8ec9e864",
      "metadata": {},
      "source": [
        "This notebook includes the implementation of StyleSpace."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "HY3C3q4mFk7m",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HY3C3q4mFk7m",
        "outputId": "71c062f3-48d9-4373-8de2-db4502e15a74"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (7.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (4.64.1)\n",
            "Collecting pyspng\n",
            "  Downloading pyspng-0.1.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (205 kB)\n",
            "\u001b[K     |████████████████████████████████| 205 kB 22.0 MB/s \n",
            "\u001b[?25hCollecting ninja\n",
            "  Downloading ninja-1.11.1-py2.py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (145 kB)\n",
            "\u001b[K     |████████████████████████████████| 145 kB 71.7 MB/s \n",
            "\u001b[?25hCollecting imageio-ffmpeg==0.4.3\n",
            "  Downloading imageio_ffmpeg-0.4.3-py3-none-manylinux2010_x86_64.whl (26.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 26.9 MB 1.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests) (1.24.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from pyspng) (1.21.6)\n",
            "Installing collected packages: pyspng, ninja, imageio-ffmpeg\n",
            "Successfully installed imageio-ffmpeg-0.4.3 ninja-1.11.1 pyspng-0.1.1\n"
          ]
        }
      ],
      "source": [
        "!pip install click requests tqdm pyspng ninja imageio-ffmpeg==0.4.3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Cbepk49HFHq4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cbepk49HFHq4",
        "outputId": "93cdc6ef-99cb-4384-abeb-735c5767f106"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'StyleSpace-pytorch'...\n",
            "remote: Enumerating objects: 57, done.\u001b[K\n",
            "remote: Counting objects: 100% (57/57), done.\u001b[K\n",
            "remote: Compressing objects: 100% (47/47), done.\u001b[K\n",
            "remote: Total 57 (delta 11), reused 37 (delta 6), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (57/57), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/xrenaa/StyleSpace-pytorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "M8bSIlA-FV2Y",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M8bSIlA-FV2Y",
        "outputId": "39765c96-1a1a-4324-e13d-b02c584f1bcf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/StyleSpace-pytorch\n"
          ]
        }
      ],
      "source": [
        "%cd ./StyleSpace-pytorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "yooIvQhjP0Mu",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yooIvQhjP0Mu",
        "outputId": "0ce7d7c5-8689-49b5-cab5-e048c94355e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.8/dist-packages (4.4.0)\n",
            "Collecting gdown\n",
            "  Downloading gdown-4.6.0-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from gdown) (3.8.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from gdown) (4.64.1)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.8/dist-packages (from gdown) (2.23.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from gdown) (1.15.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.8/dist-packages (from gdown) (4.6.3)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (2022.9.24)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Installing collected packages: gdown\n",
            "  Attempting uninstall: gdown\n",
            "    Found existing installation: gdown 4.4.0\n",
            "    Uninstalling gdown-4.4.0:\n",
            "      Successfully uninstalled gdown-4.4.0\n",
            "Successfully installed gdown-4.6.0\n",
            "/usr/local/lib/python3.8/dist-packages/gdown/cli.py:121: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1EM87UquaoQmk17Q8d5kYIAHqu0dkYqdT\n",
            "To: /content/StyleSpace-pytorch/stylegan2-ffhq-config-f.pt\n",
            "100% 381M/381M [00:08<00:00, 46.2MB/s]\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade --no-cache-dir gdown\n",
        "!gdown --id 1EM87UquaoQmk17Q8d5kYIAHqu0dkYqdT -O stylegan2-ffhq-config-f.pt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "thirty-business",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "thirty-business",
        "outputId": "02d6d3dd-513b-4cdd-abc4-39221dc11c77"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Generator(\n",
              "  (style): Sequential(\n",
              "    (0): PixelNorm()\n",
              "    (1): EqualLinear(512, 512)\n",
              "    (2): EqualLinear(512, 512)\n",
              "    (3): EqualLinear(512, 512)\n",
              "    (4): EqualLinear(512, 512)\n",
              "    (5): EqualLinear(512, 512)\n",
              "    (6): EqualLinear(512, 512)\n",
              "    (7): EqualLinear(512, 512)\n",
              "    (8): EqualLinear(512, 512)\n",
              "  )\n",
              "  (input): ConstantInput()\n",
              "  (conv1): StyledConv(\n",
              "    (conv): ModulatedConv2d(512, 512, 3, upsample=False, downsample=False)\n",
              "    (noise): NoiseInjection()\n",
              "    (activate): FusedLeakyReLU()\n",
              "  )\n",
              "  (to_rgb1): ToRGB(\n",
              "    (conv): ModulatedConv2d(512, 3, 1, upsample=False, downsample=False)\n",
              "  )\n",
              "  (convs): ModuleList(\n",
              "    (0): StyledConv(\n",
              "      (conv): ModulatedConv2d(512, 512, 3, upsample=True, downsample=False)\n",
              "      (noise): NoiseInjection()\n",
              "      (activate): FusedLeakyReLU()\n",
              "    )\n",
              "    (1): StyledConv(\n",
              "      (conv): ModulatedConv2d(512, 512, 3, upsample=False, downsample=False)\n",
              "      (noise): NoiseInjection()\n",
              "      (activate): FusedLeakyReLU()\n",
              "    )\n",
              "    (2): StyledConv(\n",
              "      (conv): ModulatedConv2d(512, 512, 3, upsample=True, downsample=False)\n",
              "      (noise): NoiseInjection()\n",
              "      (activate): FusedLeakyReLU()\n",
              "    )\n",
              "    (3): StyledConv(\n",
              "      (conv): ModulatedConv2d(512, 512, 3, upsample=False, downsample=False)\n",
              "      (noise): NoiseInjection()\n",
              "      (activate): FusedLeakyReLU()\n",
              "    )\n",
              "    (4): StyledConv(\n",
              "      (conv): ModulatedConv2d(512, 512, 3, upsample=True, downsample=False)\n",
              "      (noise): NoiseInjection()\n",
              "      (activate): FusedLeakyReLU()\n",
              "    )\n",
              "    (5): StyledConv(\n",
              "      (conv): ModulatedConv2d(512, 512, 3, upsample=False, downsample=False)\n",
              "      (noise): NoiseInjection()\n",
              "      (activate): FusedLeakyReLU()\n",
              "    )\n",
              "    (6): StyledConv(\n",
              "      (conv): ModulatedConv2d(512, 512, 3, upsample=True, downsample=False)\n",
              "      (noise): NoiseInjection()\n",
              "      (activate): FusedLeakyReLU()\n",
              "    )\n",
              "    (7): StyledConv(\n",
              "      (conv): ModulatedConv2d(512, 512, 3, upsample=False, downsample=False)\n",
              "      (noise): NoiseInjection()\n",
              "      (activate): FusedLeakyReLU()\n",
              "    )\n",
              "    (8): StyledConv(\n",
              "      (conv): ModulatedConv2d(512, 256, 3, upsample=True, downsample=False)\n",
              "      (noise): NoiseInjection()\n",
              "      (activate): FusedLeakyReLU()\n",
              "    )\n",
              "    (9): StyledConv(\n",
              "      (conv): ModulatedConv2d(256, 256, 3, upsample=False, downsample=False)\n",
              "      (noise): NoiseInjection()\n",
              "      (activate): FusedLeakyReLU()\n",
              "    )\n",
              "    (10): StyledConv(\n",
              "      (conv): ModulatedConv2d(256, 128, 3, upsample=True, downsample=False)\n",
              "      (noise): NoiseInjection()\n",
              "      (activate): FusedLeakyReLU()\n",
              "    )\n",
              "    (11): StyledConv(\n",
              "      (conv): ModulatedConv2d(128, 128, 3, upsample=False, downsample=False)\n",
              "      (noise): NoiseInjection()\n",
              "      (activate): FusedLeakyReLU()\n",
              "    )\n",
              "    (12): StyledConv(\n",
              "      (conv): ModulatedConv2d(128, 64, 3, upsample=True, downsample=False)\n",
              "      (noise): NoiseInjection()\n",
              "      (activate): FusedLeakyReLU()\n",
              "    )\n",
              "    (13): StyledConv(\n",
              "      (conv): ModulatedConv2d(64, 64, 3, upsample=False, downsample=False)\n",
              "      (noise): NoiseInjection()\n",
              "      (activate): FusedLeakyReLU()\n",
              "    )\n",
              "    (14): StyledConv(\n",
              "      (conv): ModulatedConv2d(64, 32, 3, upsample=True, downsample=False)\n",
              "      (noise): NoiseInjection()\n",
              "      (activate): FusedLeakyReLU()\n",
              "    )\n",
              "    (15): StyledConv(\n",
              "      (conv): ModulatedConv2d(32, 32, 3, upsample=False, downsample=False)\n",
              "      (noise): NoiseInjection()\n",
              "      (activate): FusedLeakyReLU()\n",
              "    )\n",
              "  )\n",
              "  (upsamples): ModuleList()\n",
              "  (to_rgbs): ModuleList(\n",
              "    (0): ToRGB(\n",
              "      (upsample): Upsample()\n",
              "      (conv): ModulatedConv2d(512, 3, 1, upsample=False, downsample=False)\n",
              "    )\n",
              "    (1): ToRGB(\n",
              "      (upsample): Upsample()\n",
              "      (conv): ModulatedConv2d(512, 3, 1, upsample=False, downsample=False)\n",
              "    )\n",
              "    (2): ToRGB(\n",
              "      (upsample): Upsample()\n",
              "      (conv): ModulatedConv2d(512, 3, 1, upsample=False, downsample=False)\n",
              "    )\n",
              "    (3): ToRGB(\n",
              "      (upsample): Upsample()\n",
              "      (conv): ModulatedConv2d(512, 3, 1, upsample=False, downsample=False)\n",
              "    )\n",
              "    (4): ToRGB(\n",
              "      (upsample): Upsample()\n",
              "      (conv): ModulatedConv2d(256, 3, 1, upsample=False, downsample=False)\n",
              "    )\n",
              "    (5): ToRGB(\n",
              "      (upsample): Upsample()\n",
              "      (conv): ModulatedConv2d(128, 3, 1, upsample=False, downsample=False)\n",
              "    )\n",
              "    (6): ToRGB(\n",
              "      (upsample): Upsample()\n",
              "      (conv): ModulatedConv2d(64, 3, 1, upsample=False, downsample=False)\n",
              "    )\n",
              "    (7): ToRGB(\n",
              "      (upsample): Upsample()\n",
              "      (conv): ModulatedConv2d(32, 3, 1, upsample=False, downsample=False)\n",
              "    )\n",
              "  )\n",
              "  (noises): Module()\n",
              ")"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from stylegan2.models import Generator\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "config = {\"latent\" : 512, \"n_mlp\" : 8, \"channel_multiplier\": 2}\n",
        "generator = Generator(\n",
        "        size= 1024,\n",
        "        style_dim=config[\"latent\"],\n",
        "        n_mlp=config[\"n_mlp\"],\n",
        "        channel_multiplier=config[\"channel_multiplier\"]\n",
        "    )\n",
        "\n",
        "generator.load_state_dict(torch.load(\"stylegan2-ffhq-config-f.pt\")['g_ema'])\n",
        "generator.eval()\n",
        "generator.cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "wooden-texture",
      "metadata": {
        "id": "wooden-texture"
      },
      "outputs": [],
      "source": [
        "from torch.nn import functional as F\n",
        "\n",
        "index = [0,1,1,2,2,3,4,4,5,6,6,7,8,8,9,10,10,11,12,12,13,14,14,15,16,16]\n",
        "\n",
        "def conv_warper(layer, input, style, noise):\n",
        "    # the conv should change\n",
        "    conv = layer.conv\n",
        "    batch, in_channel, height, width = input.shape\n",
        "\n",
        "    style = style.view(batch, 1, in_channel, 1, 1)\n",
        "    weight = conv.scale * conv.weight * style\n",
        "\n",
        "    if conv.demodulate:\n",
        "        demod = torch.rsqrt(weight.pow(2).sum([2, 3, 4]) + 1e-8)\n",
        "        weight = weight * demod.view(batch, conv.out_channel, 1, 1, 1)\n",
        "\n",
        "    weight = weight.view(\n",
        "        batch * conv.out_channel, in_channel, conv.kernel_size, conv.kernel_size\n",
        "    )\n",
        "\n",
        "    if conv.upsample:\n",
        "        input = input.view(1, batch * in_channel, height, width)\n",
        "        weight = weight.view(\n",
        "            batch, conv.out_channel, in_channel, conv.kernel_size, conv.kernel_size\n",
        "        )\n",
        "        weight = weight.transpose(1, 2).reshape(\n",
        "            batch * in_channel, conv.out_channel, conv.kernel_size, conv.kernel_size\n",
        "        )\n",
        "        out = F.conv_transpose2d(input, weight, padding=0, stride=2, groups=batch)\n",
        "        _, _, height, width = out.shape\n",
        "        out = out.view(batch, conv.out_channel, height, width)\n",
        "        out = conv.blur(out)\n",
        "\n",
        "    elif conv.downsample:\n",
        "        input = conv.blur(input)\n",
        "        _, _, height, width = input.shape\n",
        "        input = input.view(1, batch * in_channel, height, width)\n",
        "        out = F.conv2d(input, weight, padding=0, stride=2, groups=batch)\n",
        "        _, _, height, width = out.shape\n",
        "        out = out.view(batch, conv.out_channel, height, width)\n",
        "\n",
        "    else:\n",
        "        input = input.view(1, batch * in_channel, height, width)\n",
        "        out = F.conv2d(input, weight, padding=conv.padding, groups=batch)\n",
        "        _, _, height, width = out.shape\n",
        "        out = out.view(batch, conv.out_channel, height, width)\n",
        "        \n",
        "    out = layer.noise(out, noise=noise)\n",
        "    out = layer.activate(out)\n",
        "    \n",
        "    return out\n",
        "\n",
        "def decoder(G, style_space, latent, noise):\n",
        "    # an decoder warper for G\n",
        "    out = G.input(latent)\n",
        "    out = conv_warper(G.conv1, out, style_space[0], noise[0])\n",
        "    skip = G.to_rgb1(out, latent[:, 1])\n",
        "\n",
        "    i = 1\n",
        "    for conv1, conv2, noise1, noise2, to_rgb in zip(\n",
        "        G.convs[::2], G.convs[1::2], noise[1::2], noise[2::2], G.to_rgbs\n",
        "    ):\n",
        "        out = conv_warper(conv1, out, style_space[i], noise=noise1)\n",
        "        out = conv_warper(conv2, out, style_space[i+1], noise=noise2)\n",
        "        skip = to_rgb(out, latent[:, i + 2], skip)\n",
        "\n",
        "        i += 2\n",
        "\n",
        "    image = skip\n",
        "\n",
        "    return image\n",
        "\n",
        "def encoder(G, noise):\n",
        "    # an encoder warper for G\n",
        "    styles = [noise]\n",
        "    style_space = []\n",
        "    \n",
        "    styles = [G.style(s) for s in styles]\n",
        "    noise = [getattr(G.noises, 'noise_{}'.format(i)) for i in range(G.num_layers)]\n",
        "    inject_index = G.n_latent\n",
        "    latent = styles[0].unsqueeze(1).repeat(1, inject_index, 1)\n",
        "    style_space.append(G.conv1.conv.modulation(latent[:, 0]))\n",
        "\n",
        "    i = 1\n",
        "    for conv1, conv2, noise1, noise2, to_rgb in zip(\n",
        "        G.convs[::2], G.convs[1::2], noise[1::2], noise[2::2], G.to_rgbs\n",
        "    ):\n",
        "        style_space.append(conv1.conv.modulation(latent[:, i]))\n",
        "        style_space.append(conv2.conv.modulation(latent[:, i+1]))\n",
        "        i += 2\n",
        "        \n",
        "    return style_space, latent, noise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "supported-seating",
      "metadata": {
        "id": "supported-seating"
      },
      "outputs": [],
      "source": [
        "def visual(output):\n",
        "    output = (output + 1)/2\n",
        "    output = torch.clamp(output, 0, 1)\n",
        "    if output.shape[1] == 1:\n",
        "        output = torch.cat([output, output, output], 1)\n",
        "    output = output[0].detach().cpu().permute(1,2,0).numpy()\n",
        "    output = (output*255).astype(np.uint8)\n",
        "    # plt.imshow(output)\n",
        "    # plt.show()\n",
        "    return output"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "yYOa95r--5wt",
      "metadata": {
        "id": "yYOa95r--5wt"
      },
      "source": [
        "############################# our implementation start #################################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2vetqOaM-9H6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2vetqOaM-9H6",
        "outputId": "efcfda3d-04e8-4470-ecc0-fa6675ac11e9"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import time\n",
        "seed = 1\n",
        "num_images = 1000\n",
        "path = '/content/drive/MyDrive/22fall/553/project'\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "latent_code = torch.randn(num_images, 512).cuda()\n",
        "for i in tqdm(range(num_images)):\n",
        "    t0 = time.time()\n",
        "    test_input = latent_code[i].unsqueeze(0)\n",
        "\n",
        "    ## generate and save the images before manipulation\n",
        "    original, _ =  generator([test_input], False)\n",
        "    cv2.imwrite(os.path.join(path, 'stylespace_originals', str(i).zfill(4)+'.png'), visual(original)[:,:,::-1])\n",
        "    \n",
        "    ## generate and save the images with \"close mouth\" manipulation\n",
        "    style_space, latent, noise = encoder(generator, test_input)\n",
        "    style_space[index[6]][:, 259] += 10\n",
        "    image = decoder(generator, style_space, latent, noise)\n",
        "    cv2.imwrite(os.path.join(path, 'stylespace_close_mouth', str(i).zfill(4)+'.png'), visual(image)[:,:,::-1])\n",
        "\n",
        "    ## generate and save the images with \"lipstick\" manipulation\n",
        "    style_space, latent, noise = encoder(generator, test_input)\n",
        "    style_space[index[15]][:, 45] -= 3\n",
        "    image = decoder(generator, style_space, latent, noise)\n",
        "    cv2.imwrite(os.path.join(path, 'stylespace_lipstick', str(i).zfill(4)+'.png'), visual(image)[:,:,::-1])\n",
        "\n",
        "    \n",
        "    ## generate and save the images with \"close eye\" manipulation\n",
        "    style_space, latent, noise = encoder(generator, test_input)\n",
        "    style_space[index[14]][:, 239] += 30\n",
        "    image = decoder(generator, style_space, latent, noise)\n",
        "    cv2.imwrite(os.path.join(path, 'stylespace_close_eye', str(i).zfill(4)+'.png'), visual(image)[:,:,::-1])\n",
        "    print(time.time()-t0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "M6JaBSlGO4oE",
      "metadata": {
        "id": "M6JaBSlGO4oE"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.makedirs('/content/drive/MyDrive/22fall/553/project/figure_stylespace2/stylespace_originals', exist_ok=True)\n",
        "for i in range(7):\n",
        "    os.makedirs('/content/drive/MyDrive/22fall/553/project/figure_stylespace2/stylespace_close_mouth_'+str(i), exist_ok=True)\n",
        "    os.makedirs('/content/drive/MyDrive/22fall/553/project/figure_stylespace2/stylespace_close_eye_'+str(i), exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bGNiJN4yDly8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bGNiJN4yDly8",
        "outputId": "1744c138-9ba9-4af6-8883-7887a562d23b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [39:09<00:00,  2.35s/it]\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "seed = 1\n",
        "num_images = 1000\n",
        "path = '/content/drive/MyDrive/22fall/553/project/figure_stylespace'\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "latent_code = torch.randn(num_images, 512).cuda()\n",
        "for i in tqdm(range(num_images)):\n",
        "    t0 = time.time()\n",
        "    test_input = latent_code[i].unsqueeze(0)\n",
        "\n",
        "    ## generate and save the images before manipulation\n",
        "    original, _ =  generator([test_input], False)\n",
        "    cv2.imwrite(os.path.join(path, 'stylespace_originals', str(i).zfill(4)+'.png'), visual(original)[:,:,::-1])\n",
        "\n",
        "    ## generate and save the images with \"close mouth\" manipulation of different degrees\n",
        "    for j in range(7):\n",
        "        style_space, latent, noise = encoder(generator, test_input)\n",
        "        style_space[index[6]][:, 259] += j*10/6\n",
        "        image = decoder(generator, style_space, latent, noise)\n",
        "        cv2.imwrite(os.path.join(path, 'stylespace_close_mouth_'+str(j), str(i).zfill(4)+'.png'), visual(image)[:,:,::-1])\n",
        "\n",
        "    ## generate and save the images with \"close eye\" manipulation of different degrees\n",
        "    for j in range(7):\n",
        "        style_space, latent, noise = encoder(generator, test_input)\n",
        "        style_space[index[14]][:, 239] += j*30/6\n",
        "        image = decoder(generator, style_space, latent, noise)\n",
        "        cv2.imwrite(os.path.join(path, 'stylespace_close_eye_'+str(j), str(i).zfill(4)+'.png'), visual(image)[:,:,::-1])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "0d38abf0",
      "metadata": {},
      "source": [
        "############################# our implementation end ###################################"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "yYOa95r--5wt"
      ],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
